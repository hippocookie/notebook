# Intro

## 什么是大数据？

大数据”是指传统数据处理应用软件时，不足以处理的大的或者复杂的数据集的术语。

核心技术理念

**第一个，是能够伸缩到一千台服务器以上的分布式数据处理集群的技术**

在Google发表GFS论文之前，业界就有处理海量数据（TB）的公司和方案，一般单个集群为几十个服务器，而GFS论文把数据处理拉上了一个新台阶，单个集群里可以有成千上万个节点，可以处理PB级别的数据。

**第二个，是这个上千个节点的集群，是采用廉价的 PC 架构搭建起来的**

摩尔定律：集成电路上可以容纳的晶体管数目在大约每经过18个月便会增加一倍，性能也将提升一倍。为了管理更大量的数据，我们需要使用更好的硬件（CPU，内存，硬盘等），而GFS搭建集群使用的硬件与普通PC并大的差异。集群可由小增长到大，让处理海量数据变得便宜。

**最后一个，则是“把数据中心当作是一台计算机”（Datacenter as a Computer）**

易于操作，不需要了解底层知识。

## 三驾马车

### GFS，Google

2003年，解决了数据存储问题。

### MapReduce，Google

2004年，数据计算。

### Bigtable，Google

2006年，数据高性能随机读写。

### Chubby，Google

2006年，分布式锁，解决数据一致性。

### Thrift，Facebook

2007年，数据序列化，解决通信问题。

### Hive，Facebook（Pig，Sawzall）

2009年，HQL编写MapReduce，降低编写难度。

### Dremel，Google

2010年，列存 + 并行，解决MapReduce高延时问题。

### Spark，Berkeley

2010年，内存计算，提升性能。

### Megastore，Google

2011年，类SQL接口，Schema，跨行事务。

### Spanner，Google

2012年，全局一致性，解决异地多活，跨数据中心问题。

### Dataflow，Google（Flink，Apache Beam）

2015年，流批一体。

### Kubernetes，Google

2016年，资源管理调度。
